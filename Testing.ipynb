{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trainer import utils, model, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = utils.preprocess('./datasets/credit-card-fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26066</th>\n",
       "      <td>-1.282867</td>\n",
       "      <td>-0.499705</td>\n",
       "      <td>0.708694</td>\n",
       "      <td>1.425333</td>\n",
       "      <td>0.803725</td>\n",
       "      <td>-0.403973</td>\n",
       "      <td>-0.705060</td>\n",
       "      <td>1.296585</td>\n",
       "      <td>-0.217569</td>\n",
       "      <td>-0.736349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242975</td>\n",
       "      <td>0.252274</td>\n",
       "      <td>0.517166</td>\n",
       "      <td>0.104957</td>\n",
       "      <td>0.720152</td>\n",
       "      <td>0.269228</td>\n",
       "      <td>-0.347839</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.042301</td>\n",
       "      <td>0.222495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248503</th>\n",
       "      <td>1.245705</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.759606</td>\n",
       "      <td>-0.451130</td>\n",
       "      <td>-0.679557</td>\n",
       "      <td>1.106971</td>\n",
       "      <td>-0.279973</td>\n",
       "      <td>0.908437</td>\n",
       "      <td>-0.036138</td>\n",
       "      <td>-0.264577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092291</td>\n",
       "      <td>0.402435</td>\n",
       "      <td>1.312470</td>\n",
       "      <td>-0.114381</td>\n",
       "      <td>0.318144</td>\n",
       "      <td>-0.730513</td>\n",
       "      <td>-0.246703</td>\n",
       "      <td>0.492998</td>\n",
       "      <td>0.317484</td>\n",
       "      <td>-0.281304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40528</th>\n",
       "      <td>-1.148412</td>\n",
       "      <td>1.197044</td>\n",
       "      <td>-0.173413</td>\n",
       "      <td>0.582497</td>\n",
       "      <td>-0.220047</td>\n",
       "      <td>-0.611500</td>\n",
       "      <td>-0.253002</td>\n",
       "      <td>-0.435967</td>\n",
       "      <td>0.158689</td>\n",
       "      <td>0.239026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132103</td>\n",
       "      <td>-0.062904</td>\n",
       "      <td>-0.203170</td>\n",
       "      <td>0.122115</td>\n",
       "      <td>0.048525</td>\n",
       "      <td>-0.009253</td>\n",
       "      <td>0.919735</td>\n",
       "      <td>-0.062561</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.345233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181526</th>\n",
       "      <td>0.635889</td>\n",
       "      <td>1.203094</td>\n",
       "      <td>-0.894067</td>\n",
       "      <td>-0.677269</td>\n",
       "      <td>4.107823</td>\n",
       "      <td>-0.135763</td>\n",
       "      <td>1.080577</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.268341</td>\n",
       "      <td>-0.365852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303302</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.336555</td>\n",
       "      <td>-0.163945</td>\n",
       "      <td>0.692393</td>\n",
       "      <td>-0.091617</td>\n",
       "      <td>0.053281</td>\n",
       "      <td>-0.079604</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.980572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193490</th>\n",
       "      <td>0.744295</td>\n",
       "      <td>1.837395</td>\n",
       "      <td>-0.088287</td>\n",
       "      <td>-2.268945</td>\n",
       "      <td>1.007227</td>\n",
       "      <td>0.989485</td>\n",
       "      <td>-0.377806</td>\n",
       "      <td>0.775140</td>\n",
       "      <td>-0.252736</td>\n",
       "      <td>-0.360622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>0.209571</td>\n",
       "      <td>0.376056</td>\n",
       "      <td>-0.138268</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.455206</td>\n",
       "      <td>-0.515871</td>\n",
       "      <td>-0.062162</td>\n",
       "      <td>-0.052197</td>\n",
       "      <td>0.128140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "26066  -1.282867 -0.499705  0.708694  1.425333  0.803725 -0.403973 -0.705060   \n",
       "248503  1.245705  0.023911  0.759606 -0.451130 -0.679557  1.106971 -0.279973   \n",
       "40528  -1.148412  1.197044 -0.173413  0.582497 -0.220047 -0.611500 -0.253002   \n",
       "181526  0.635889  1.203094 -0.894067 -0.677269  4.107823 -0.135763  1.080577   \n",
       "193490  0.744295  1.837395 -0.088287 -2.268945  1.007227  0.989485 -0.377806   \n",
       "\n",
       "              V7        V8        V9    ...          V20       V21       V22  \\\n",
       "26066   1.296585 -0.217569 -0.736349    ...     0.242975  0.252274  0.517166   \n",
       "248503  0.908437 -0.036138 -0.264577    ...     0.092291  0.402435  1.312470   \n",
       "40528  -0.435967  0.158689  0.239026    ...    -0.132103 -0.062904 -0.203170   \n",
       "181526  0.007601  0.268341 -0.365852    ...     0.303302  0.323461  0.336555   \n",
       "193490  0.775140 -0.252736 -0.360622    ...    -0.020674  0.209571  0.376056   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "26066   0.104957  0.720152  0.269228 -0.347839 -0.000305  0.042301  0.222495  \n",
       "248503 -0.114381  0.318144 -0.730513 -0.246703  0.492998  0.317484 -0.281304  \n",
       "40528   0.122115  0.048525 -0.009253  0.919735 -0.062561 -0.005830 -0.345233  \n",
       "181526 -0.163945  0.692393 -0.091617  0.053281 -0.079604  0.004682  0.980572  \n",
       "193490 -0.138268  0.216634  0.455206 -0.515871 -0.062162 -0.052197  0.128140  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Pytorch Dataloaders\n",
    "xdl = utils.create_dataloader(X_train.values, 256)\n",
    "vdl = utils.create_dataloader(X_val.values, 256)\n",
    "tdl = utils.create_dataloader(X_test.values, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(X_train.columns)\n",
    "autoencoder = model.compile_model(num_features, 18, 8)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Loss: 0.6399   Val_Loss: 0.6719\n",
      "Epoch: 1   Loss: 0.5984   Val_Loss: 0.6369\n",
      "Epoch: 2   Loss: 0.5765   Val_Loss: 0.6179\n",
      "Epoch: 3   Loss: 0.5664   Val_Loss: 0.6094\n",
      "Epoch: 4   Loss: 0.5580   Val_Loss: 0.6012\n",
      "Epoch: 5   Loss: 0.5535   Val_Loss: 0.5963\n",
      "Epoch: 6   Loss: 0.5508   Val_Loss: 0.5930\n",
      "Epoch: 7   Loss: 0.5477   Val_Loss: 0.5893\n",
      "Epoch: 8   Loss: 0.5443   Val_Loss: 0.5847\n",
      "Epoch: 9   Loss: 0.5396   Val_Loss: 0.5810\n",
      "Epoch: 10   Loss: 0.5364   Val_Loss: 0.5777\n",
      "Epoch: 11   Loss: 0.5336   Val_Loss: 0.5746\n",
      "Epoch: 12   Loss: 0.5316   Val_Loss: 0.5721\n",
      "Epoch: 13   Loss: 0.5296   Val_Loss: 0.5696\n",
      "Epoch: 14   Loss: 0.5278   Val_Loss: 0.5676\n",
      "Epoch: 15   Loss: 0.5267   Val_Loss: 0.5656\n",
      "Epoch: 16   Loss: 0.5259   Val_Loss: 0.5644\n",
      "Epoch: 17   Loss: 0.5247   Val_Loss: 0.5637\n",
      "Epoch: 18   Loss: 0.5242   Val_Loss: 0.5628\n",
      "Epoch: 19   Loss: 0.5239   Val_Loss: 0.5626\n",
      "Epoch: 20   Loss: 0.5232   Val_Loss: 0.5616\n",
      "Epoch: 21   Loss: 0.5229   Val_Loss: 0.5613\n",
      "Epoch: 22   Loss: 0.5229   Val_Loss: 0.5605\n",
      "Epoch: 23   Loss: 0.5229   Val_Loss: 0.5602\n",
      "Epoch: 24   Loss: 0.5233   Val_Loss: 0.5604\n",
      "Epoch: 25   Loss: 0.5212   Val_Loss: 0.5583\n",
      "Epoch: 26   Loss: 0.5203   Val_Loss: 0.5575\n",
      "Epoch: 27   Loss: 0.5200   Val_Loss: 0.5569\n",
      "Epoch: 28   Loss: 0.5194   Val_Loss: 0.5565\n",
      "Epoch: 29   Loss: 0.5202   Val_Loss: 0.5565\n",
      "Epoch: 30   Loss: 0.5192   Val_Loss: 0.5558\n",
      "Epoch: 31   Loss: 0.5188   Val_Loss: 0.5554\n",
      "Epoch: 32   Loss: 0.5184   Val_Loss: 0.5552\n",
      "Epoch: 33   Loss: 0.5187   Val_Loss: 0.5550\n",
      "Epoch: 34   Loss: 0.5185   Val_Loss: 0.5547\n",
      "Epoch: 35   Loss: 0.5180   Val_Loss: 0.5545\n",
      "Epoch: 36   Loss: 0.5177   Val_Loss: 0.5543\n",
      "Epoch: 37   Loss: 0.5177   Val_Loss: 0.5540\n",
      "Epoch: 38   Loss: 0.5180   Val_Loss: 0.5538\n",
      "Epoch: 39   Loss: 0.5183   Val_Loss: 0.5535\n",
      "Epoch: 40   Loss: 0.5181   Val_Loss: 0.5533\n",
      "Epoch: 41   Loss: 0.5177   Val_Loss: 0.5530\n",
      "Epoch: 42   Loss: 0.5200   Val_Loss: 0.5551\n",
      "Epoch: 43   Loss: 0.5174   Val_Loss: 0.5524\n",
      "Epoch: 44   Loss: 0.5168   Val_Loss: 0.5520\n",
      "Epoch: 45   Loss: 0.5159   Val_Loss: 0.5516\n",
      "Epoch: 46   Loss: 0.5142   Val_Loss: 0.5514\n",
      "Epoch: 47   Loss: 0.5138   Val_Loss: 0.5514\n",
      "Epoch: 48   Loss: 0.5141   Val_Loss: 0.5505\n",
      "Epoch: 49   Loss: 0.5138   Val_Loss: 0.5501\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'autoencoder.pt'\n",
    "task.train_model_and_save(50, autoencoder, loss, optimizer, xdl, vdl, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.ipynb  autoencoder.pt \u001b[34mdatasets\u001b[m\u001b[m       \u001b[34mtrainer\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
